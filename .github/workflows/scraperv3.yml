name: scraperv3

on:
  schedule:
    - cron: "0 4 * * 2" # in the midnight Monday to Tuesday UTC-4 (Tuesday at 04.00 AM UTC)
    - cron: "0 4 * * 4" # Thursday
    - cron: "0 4 * * 6" # Saturday

# Add concurrency control to prevent simultaneous workflow runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  scraping:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Fetch complete history

      # [Your existing Python setup steps]

      - name: Commit result
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Apply changes
          git add history/*.json

              # Create commit
          timestamp=$(TZ='America/New_York' date +'%a, %F at %H:%M %Z')
          git commit -m "Scraping updated: ${timestamp}" || exit 0
          
          # Force push to main branch
          git push --force origin HEAD:main

  forwarding:
    runs-on: ubuntu-latest
    needs: scraping

    steps:
      # [Your existing R setup steps]

      - name: Commit data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Fetch latest changes
          git fetch origin main

          # Ensure we're on main branch
          git checkout main

          # Reset to match remote main
          git reset --hard origin/main

              # Add your changes
          git add *.rds history/foreclose/*.csv history/taxdeed/*.csv
          
          # Create commit
          timestamp=$(TZ='America/New_York' date +'%a, %F at %H:%M %Z')
          git commit -m "Data updated: ${timestamp}" || exit 0
          
          # Force push to main branch
          git push --force origin HEAD:main