name: python-scraper

on:
  push:
    branches:
      - 'python'

jobs:
  scraping-time:
    runs-on: ubuntu-latest  
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
      
      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'
      
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.1.1'
      
      - name: Install python module
        run: |
          python -m pip install --upgrade pip
          pip install playwright
          playwright install --with-deps firefox
      
      - name: Install R library
        run: |
          sudo apt-get install libcurl4-openssl-dev
          Rscript -e 'install.packages(c("dplyr", "googlesheets4", "jsonlite"))'
      
      - name: Run scraper and forwarder
        env:
          CRED_PATH: ${{ secrets.CRED_PATH }}
          SECRET_TOKEN: ${{ secrets.SECRET_TOKEN }}
          SHEETS_FORECLOSE: ${{ secrets.SHEETS_FORECLOSE }}
          SHEETS_TAXDEED: ${{ secrets.SHEETS_TAXDEED }}
          SHEETS_TEST: ${{ secrets.SHEETS_TEST }}
        run: | 
          echo $SECRET_TOKEN >> $CRED_PATH
          python main.py
          Rscript forwarder.R
          rm $CRED_PATH
          
      - name: Commit result
        shell: bash {0}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add history/*.json *.rds history/foreclose/*.csv history/taxdeed/*.csv
          timestamp=$(TZ='America/New_York' date +'%a, %F at %H:%M %Z')
          git commit -m "Updated: ${timestamp}" || exit 0
          git push
